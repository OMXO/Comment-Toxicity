# Comment-Toxicity
This project implements a deep learning-based multi-label text classification model to detect different types of toxic comments. The model is trained to classify user-generated comments into multiple categories of toxicity, such as:  ✅ Toxic  ✅ Severe Toxic  ✅ Obscene  ✅ Threat  ✅ Insult  ✅ Identity Hate
